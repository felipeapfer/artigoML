{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "database = 'database.sqlite'\n",
    "conn = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uk = pd.read_csv('./leagues/1729.csv',index_col='Unnamed: 0')\n",
    "de = pd.read_csv('./leagues/7809.csv',index_col='Unnamed: 0')\n",
    "fr = pd.read_csv('./leagues/4769.csv',index_col='Unnamed: 0')\n",
    "it = pd.read_csv('./leagues/10257.csv',index_col='Unnamed: 0')\n",
    "es = pd.read_csv('./leagues/21518.csv',index_col='Unnamed: 0')\n",
    "pt = pd.read_csv('./leagues/17642.csv',index_col='Unnamed: 0')\n",
    "\n",
    "data= pd.concat([uk,de])\n",
    "data1= pd.concat([es,fr])\n",
    "data= pd.concat([data,it])\n",
    "data1= pd.concat([data1,pt])\n",
    "data= pd.concat([data,data1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft = ['home_V','home_D','home_E','home_GF','home_AVG_GF','home_GS','home_AVG_GS','home_VG','home_DG','home_EG','home_GFG','home_AVG_GFG','home_GSG','home_AVG_GSG','away_V','away_D','away_E','away_GF','away_AVG_GF','away_GS','away_AVG_GS','away_VG','away_DG','away_EG','away_GFG','away_AVG_GFG','away_GSG','away_AVG_GSG','h_buildUpPlaySpeed','h_buildUpPlaySpeedClass','h_buildUpPlayDribblingClass','h_buildUpPlayPassing','h_buildUpPlayPassingClass','h_buildUpPlayPositioningClass','h_chanceCreationPassing','h_chanceCreationPassingClass','h_chanceCreationCrossing','h_chanceCreationCrossingClass','h_chanceCreationShooting','h_chanceCreationShootingClass','h_chanceCreationPositioningClass','h_defencePressure','h_defencePressureClass','h_defenceAggression','h_defenceAggressionClass','h_defenceTeamWidth','h_defenceTeamWidthClass','h_defenceDefenderLineClass','a_buildUpPlaySpeed','a_buildUpPlaySpeedClass','a_buildUpPlayDribblingClass','a_buildUpPlayPassing','a_buildUpPlayPassingClass','a_buildUpPlayPositioningClass','a_chanceCreationPassing','a_chanceCreationPassingClass','a_chanceCreationCrossing','a_chanceCreationCrossingClass','a_chanceCreationShooting','a_chanceCreationShootingClass','a_chanceCreationPositioningClass','a_defencePressure','a_defencePressureClass','a_defenceAggression','a_defenceAggressionClass','a_defenceTeamWidth','a_defenceTeamWidthClass','a_defenceDefenderLineClass','h_avg_height','h_avg_weight','a_avg_height','a_avg_weight','h_overall','h_potential','h_def','h_mid','h_att','a_overall','a_potential','a_def','a_mid','a_att','a_date','h_date','id','season','stage','home_team_api_id','away_team_api_id','B365H','B365D','B365A','formation_h','formation_a','league_id'] \n",
    "\n",
    "#for column in ft:\n",
    "#    data[column]=(data[column] - data[column].mean()) / data[column].std()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_V</th>\n",
       "      <th>home_D</th>\n",
       "      <th>home_E</th>\n",
       "      <th>home_GF</th>\n",
       "      <th>home_AVG_GF</th>\n",
       "      <th>home_GS</th>\n",
       "      <th>home_AVG_GS</th>\n",
       "      <th>home_VG</th>\n",
       "      <th>home_DG</th>\n",
       "      <th>home_EG</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>formation_h</th>\n",
       "      <th>formation_a</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9825</td>\n",
       "      <td>8654</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10252</td>\n",
       "      <td>8658</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.50</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8668</td>\n",
       "      <td>10194</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.50</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10261</td>\n",
       "      <td>8472</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8602</td>\n",
       "      <td>8456</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.73</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8655</td>\n",
       "      <td>8455</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.44</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9879</td>\n",
       "      <td>8528</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10260</td>\n",
       "      <td>8602</td>\n",
       "      <td>1.22</td>\n",
       "      <td>6.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9825</td>\n",
       "      <td>10261</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8650</td>\n",
       "      <td>8455</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.00</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8472</td>\n",
       "      <td>10194</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8655</td>\n",
       "      <td>8528</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9879</td>\n",
       "      <td>10252</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8658</td>\n",
       "      <td>8654</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8483</td>\n",
       "      <td>8668</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8586</td>\n",
       "      <td>8472</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8654</td>\n",
       "      <td>8659</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.20</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8602</td>\n",
       "      <td>9825</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.67</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10194</td>\n",
       "      <td>8658</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8528</td>\n",
       "      <td>8650</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.75</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10261</td>\n",
       "      <td>8655</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8455</td>\n",
       "      <td>9879</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>15.00</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8586</td>\n",
       "      <td>8655</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.50</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8654</td>\n",
       "      <td>8483</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10252</td>\n",
       "      <td>10260</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.80</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8668</td>\n",
       "      <td>9825</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10261</td>\n",
       "      <td>9879</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8456</td>\n",
       "      <td>8658</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10194</td>\n",
       "      <td>8650</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8528</td>\n",
       "      <td>8659</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.88</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>10238</td>\n",
       "      <td>6403</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.90</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>9807</td>\n",
       "      <td>7842</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.20</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>9772</td>\n",
       "      <td>10214</td>\n",
       "      <td>1.10</td>\n",
       "      <td>9.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>10264</td>\n",
       "      <td>9768</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.44</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>158085</td>\n",
       "      <td>9807</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8613</td>\n",
       "      <td>9768</td>\n",
       "      <td>9.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8348</td>\n",
       "      <td>9773</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10214</td>\n",
       "      <td>10238</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7841</td>\n",
       "      <td>10215</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.60</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7844</td>\n",
       "      <td>10264</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10215</td>\n",
       "      <td>10212</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.05</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6403</td>\n",
       "      <td>10214</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10264</td>\n",
       "      <td>158085</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9773</td>\n",
       "      <td>9807</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7841</td>\n",
       "      <td>8613</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10238</td>\n",
       "      <td>7842</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.88</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9768</td>\n",
       "      <td>7844</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9772</td>\n",
       "      <td>9768</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7842</td>\n",
       "      <td>7841</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.50</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8348</td>\n",
       "      <td>10238</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7844</td>\n",
       "      <td>10215</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10214</td>\n",
       "      <td>8613</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.33</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9773</td>\n",
       "      <td>10264</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9.50</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10212</td>\n",
       "      <td>6403</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8613</td>\n",
       "      <td>10212</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6403</td>\n",
       "      <td>7844</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10238</td>\n",
       "      <td>158085</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.75</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10264</td>\n",
       "      <td>9807</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9768</td>\n",
       "      <td>7842</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7841</td>\n",
       "      <td>10214</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8791 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    home_V  home_D  home_E  home_GF  home_AVG_GF  home_GS  home_AVG_GS  \\\n",
       "0        1       1       0        4     2.000000        4     2.000000   \n",
       "0        0       0       2        1     0.500000        1     0.500000   \n",
       "0        1       1       0        2     1.000000        1     0.500000   \n",
       "0        0       1       1        3     1.500000        4     2.000000   \n",
       "0        0       1       1        2     1.000000        3     1.500000   \n",
       "0        0       0       2        1     0.500000        1     0.500000   \n",
       "0        0       1       1        1     0.500000        2     1.000000   \n",
       "0        1       0       1        4     2.000000        2     1.000000   \n",
       "0        2       1       0        5     1.666667        4     1.333333   \n",
       "0        1       1       1        5     1.666667        5     1.666667   \n",
       "0        1       0       1        1     0.500000        0     0.000000   \n",
       "0        0       1       1        1     0.500000        2     1.000000   \n",
       "0        1       1       1        3     1.000000        2     0.666667   \n",
       "0        1       1       1        2     0.666667        2     0.666667   \n",
       "0        1       2       0        5     1.666667        6     2.000000   \n",
       "0        1       0       1        3     1.500000        2     1.000000   \n",
       "0        0       1       1        2     1.000000        3     1.500000   \n",
       "0        1       0       1        3     1.500000        2     1.000000   \n",
       "0        1       1       0        2     1.000000        2     1.000000   \n",
       "0        1       0       1        3     1.500000        1     0.500000   \n",
       "0        1       0       1        7     3.500000        3     1.500000   \n",
       "0        2       0       0        4     2.000000        0     0.000000   \n",
       "0        0       0       2        2     1.000000        2     1.000000   \n",
       "0        0       1       1        3     1.500000        4     2.000000   \n",
       "0        1       0       2        3     1.000000        2     0.666667   \n",
       "0        2       0       1        4     1.333333        1     0.333333   \n",
       "0        1       1       1        8     2.666667        5     1.666667   \n",
       "0        0       1       1        0     0.000000        3     1.500000   \n",
       "0        1       1       0        4     2.000000        4     2.000000   \n",
       "0        0       0       2        2     1.000000        2     1.000000   \n",
       "..     ...     ...     ...      ...          ...      ...          ...   \n",
       "0        0       2       0        0     0.000000        2     1.000000   \n",
       "0        0       1       1        1     0.500000        3     1.500000   \n",
       "0        2       0       0        3     1.500000        1     0.500000   \n",
       "0        2       0       1        7     2.333333        3     1.000000   \n",
       "0        1       1       0        2     1.000000        3     1.500000   \n",
       "0        1       1       0        1     0.500000        1     0.500000   \n",
       "0        0       1       1        0     0.000000        2     1.000000   \n",
       "0        2       0       0        3     1.500000        0     0.000000   \n",
       "0        1       1       0        2     1.000000        2     1.000000   \n",
       "0        1       0       1        2     1.000000        1     0.500000   \n",
       "0        0       3       0        1     0.333333        9     3.000000   \n",
       "0        0       1       1        1     0.500000        4     2.000000   \n",
       "0        2       0       0        9     4.500000        1     0.500000   \n",
       "0        2       0       0        3     1.500000        0     0.000000   \n",
       "0        2       1       0        3     1.000000        2     0.666667   \n",
       "0        0       0       2        4     2.000000        4     2.000000   \n",
       "0        1       0       1        2     1.000000        1     0.500000   \n",
       "0        3       0       0       12     4.000000        2     0.666667   \n",
       "0        2       0       0        3     1.500000        1     0.500000   \n",
       "0        0       0       2        2     1.000000        2     1.000000   \n",
       "0        1       1       0        1     0.500000        1     0.500000   \n",
       "0        1       0       1        3     1.500000        1     0.500000   \n",
       "0        3       0       0        7     2.333333        0     0.000000   \n",
       "0        2       0       0        6     3.000000        2     1.000000   \n",
       "0        0       1       1        0     0.000000        1     0.500000   \n",
       "0        1       1       0        3     1.500000        4     2.000000   \n",
       "0        1       0       1        3     1.500000        2     1.000000   \n",
       "0        1       0       1        5     2.500000        1     0.500000   \n",
       "0        2       0       0        6     3.000000        1     0.500000   \n",
       "0        2       1       0        3     1.000000        2     0.666667   \n",
       "\n",
       "    home_VG  home_DG  home_EG   ...    season  stage  home_team_api_id  \\\n",
       "0         5        2        2   ...         0     10              9825   \n",
       "0         3        4        2   ...         0     10             10252   \n",
       "0         2        3        4   ...         0     10              8668   \n",
       "0         3        4        2   ...         0     10             10261   \n",
       "0         1        5        3   ...         0     10              8602   \n",
       "0         2        4        3   ...         0     10              8655   \n",
       "0         1        2        6   ...         0     10              9879   \n",
       "0         5        0        5   ...         0     11             10260   \n",
       "0         6        2        2   ...         0     11              9825   \n",
       "0         3        4        3   ...         0     11              8650   \n",
       "0         2        2        6   ...         0     11              8472   \n",
       "0         2        5        3   ...         0     11              8655   \n",
       "0         2        2        6   ...         0     11              9879   \n",
       "0         2        3        5   ...         0     11              8658   \n",
       "0         4        5        1   ...         0     11              8483   \n",
       "0         4        4        3   ...         0     12              8586   \n",
       "0         1        6        4   ...         0     12              8654   \n",
       "0         2        6        3   ...         0     12              8602   \n",
       "0         3        7        1   ...         0     12             10194   \n",
       "0         2        5        4   ...         0     12              8528   \n",
       "0         5        4        2   ...         0     12             10261   \n",
       "0         8        2        1   ...         0     12              8455   \n",
       "0         4        4        4   ...         0     13              8586   \n",
       "0         1        6        5   ...         0     13              8654   \n",
       "0         4        4        4   ...         0     13             10252   \n",
       "0         3        3        6   ...         0     13              8668   \n",
       "0         5        5        2   ...         0     13             10261   \n",
       "0         6        3        3   ...         0     13              8456   \n",
       "0         4        7        1   ...         0     13             10194   \n",
       "0         2        5        5   ...         0     13              8528   \n",
       "..      ...      ...      ...   ...       ...    ...               ...   \n",
       "0         6       16       11   ...         5     34             10238   \n",
       "0         9       13       11   ...         5     34              9807   \n",
       "0        28        4        1   ...         5     34              9772   \n",
       "0        16        7       10   ...         5     34             10264   \n",
       "0         2        1        2   ...         5      6            158085   \n",
       "0         2        2        1   ...         5      6              8613   \n",
       "0         0        4        1   ...         5      6              8348   \n",
       "0         2        3        0   ...         5      6             10214   \n",
       "0         2        1        2   ...         5      6              7841   \n",
       "0         1        1        3   ...         5      6              7844   \n",
       "0         0        6        0   ...         5      7             10215   \n",
       "0         2        2        2   ...         5      7              6403   \n",
       "0         4        2        0   ...         5      7             10264   \n",
       "0         4        0        2   ...         5      7              9773   \n",
       "0         3        1        2   ...         5      7              7841   \n",
       "0         1        1        4   ...         5      7             10238   \n",
       "0         4        0        2   ...         5      7              9768   \n",
       "0         4        2        1   ...         5      8              9772   \n",
       "0         4        3        0   ...         5      8              7842   \n",
       "0         0        4        3   ...         5      8              8348   \n",
       "0         1        3        3   ...         5      8              7844   \n",
       "0         2        4        1   ...         5      8             10214   \n",
       "0         5        0        2   ...         5      8              9773   \n",
       "0         2        3        2   ...         5      8             10212   \n",
       "0         2        3        3   ...         5      9              8613   \n",
       "0         4        2        2   ...         5      9              6403   \n",
       "0         3        1        4   ...         5      9             10238   \n",
       "0         4        2        2   ...         5      9             10264   \n",
       "0         6        0        2   ...         5      9              9768   \n",
       "0         4        1        3   ...         5      9              7841   \n",
       "\n",
       "    away_team_api_id  B365H  B365D  B365A  formation_h  formation_a  Output  \n",
       "0               8654   1.17   7.00  17.00            8            5       H  \n",
       "0               8658   1.80   3.60   4.50           13           13       D  \n",
       "0              10194   1.57   3.75   6.50           13           12       H  \n",
       "0               8472   2.20   3.20   3.50           12            8       H  \n",
       "0               8456   5.50   3.40   1.73           13           13       H  \n",
       "0               8455   7.50   4.33   1.44           13           11       A  \n",
       "0               8528   1.91   3.40   4.20           13           12       H  \n",
       "0               8602   1.22   6.00  15.00           13           13       H  \n",
       "0              10261   1.29   5.50  11.00           11           12       A  \n",
       "0               8455   3.80   3.40   2.00           12           11       H  \n",
       "0              10194   2.10   3.20   3.75           12           12       H  \n",
       "0               8528   1.80   3.60   4.50            5           13       H  \n",
       "0              10252   2.20   3.25   3.40           13           13       D  \n",
       "0               8654   1.91   3.40   4.20           12           11       D  \n",
       "0               8668   4.50   3.60   1.80           11           13       D  \n",
       "0               8472   1.53   4.00   6.50           13           13       D  \n",
       "0               8659   2.30   3.25   3.20           12           13       D  \n",
       "0               9825   5.50   3.60   1.67           13            8       A  \n",
       "0               8658   2.10   3.20   3.75           12           12       H  \n",
       "0               8650   4.75   3.60   1.75           13           12       D  \n",
       "0               8655   1.91   3.40   4.20           12            1       A  \n",
       "0               9879   1.20   6.50  15.00           11           13       H  \n",
       "0               8655   1.57   3.80   6.50           12           15       H  \n",
       "0               8483   1.91   3.60   4.00           12            8       D  \n",
       "0              10260   4.50   3.60   1.80           13           12       D  \n",
       "0               9825   3.40   3.30   2.20           13            8       A  \n",
       "0               9879   1.91   3.40   4.20           12           12       D  \n",
       "0               8658   1.40   4.50   8.50            8           12       D  \n",
       "0               8650   3.75   3.25   2.10           12            8       H  \n",
       "0               8659   2.50   3.25   2.88           13           13       H  \n",
       "..               ...    ...    ...    ...          ...          ...     ...  \n",
       "0               6403   2.30   3.50   2.90            8            5       D  \n",
       "0               7842   3.10   3.50   2.20            6            5       H  \n",
       "0              10214   1.10   9.00  21.00            3            6       H  \n",
       "0               9768   7.00   4.33   1.44            8            7       A  \n",
       "0               9807   2.40   3.00   3.20            6            6       D  \n",
       "0               9768   9.50   5.00   1.33            8            7       D  \n",
       "0               9773  15.00   5.50   1.22            7            6       D  \n",
       "0              10238   1.91   3.40   4.00            7            6       D  \n",
       "0              10215   1.62   3.60   6.00            2            7       H  \n",
       "0              10264   3.50   3.00   2.25            6            7       A  \n",
       "0              10212   4.00   3.10   2.05            7            6       H  \n",
       "0              10214   2.20   3.50   3.10            7            6       H  \n",
       "0             158085   1.53   4.00   6.00            8            6       D  \n",
       "0               9807   1.14   7.00  21.00            7            6       H  \n",
       "0               8613   2.05   3.30   3.60            7            6       H  \n",
       "0               7842   2.50   3.20   2.88            8            6       H  \n",
       "0               7844   1.29   5.50  10.00            8            6       H  \n",
       "0               9768   2.20   3.20   3.40            8            7       A  \n",
       "0               7841   2.20   3.10   3.50            7            6       D  \n",
       "0              10238   2.30   3.20   3.20            8            7       A  \n",
       "0              10215   1.70   3.60   5.00            7            5       D  \n",
       "0               8613   1.91   3.25   4.33            7            5       D  \n",
       "0              10264   1.33   4.75   9.50            7            7       D  \n",
       "0               6403   1.91   3.40   4.00            7            6       A  \n",
       "0              10212   2.70   3.20   2.60            7            6       A  \n",
       "0               7844   2.15   3.20   3.50            6            5       A  \n",
       "0             158085   2.10   3.10   3.75            8            5       D  \n",
       "0               9807   1.50   4.00   6.50            8            5       H  \n",
       "0               7842   1.20   6.00  15.00            3            5       H  \n",
       "0              10214   2.30   3.10   3.30            6            6       H  \n",
       "\n",
       "[8791 rows x 97 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.981429559041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing \n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), data[ft], data['Output'], cv=10, scoring='log_loss')\n",
    "print scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pure_data = pd.read_csv('pure_data.csv',index_col='Unnamed: 0')\n",
    "pure_formation = pd.read_csv('pure_formation.csv',index_col='Unnamed: 0')\n",
    "\n",
    "ft_pure_data=pure_data.columns.values[0:len(pure_data.columns.values)-1]\n",
    "ft_pure_formation=['country_id', 'league_id', 'season', 'stage', 'date',\n",
    "       'match_api_id', 'home_team_api_id', 'away_team_api_id', 'B365H',\n",
    "       'B365D', 'B365A', 'formation_h', 'formation_a']\n",
    "pure_formation['formation_a'] = le.fit_transform(pure_formation['formation_a'].astype('str')) \n",
    "pure_formation['formation_h'] = le.fit_transform(pure_formation['formation_h'].astype('str')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19685, 56)\n",
      "(19685, 14)\n"
     ]
    }
   ],
   "source": [
    "print pure_data.shape\n",
    "print pure_formation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Data\n",
      "-1.06908234659\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), pure_data[ft_pure_data], pure_data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Pure Data\"\n",
    "print scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country_id', 'league_id', 'season', 'stage', 'date', 'match_api_id', 'home_team_api_id', 'away_team_api_id', 'B365H', 'B365D', 'B365A', 'formation_h', 'formation_a']\n",
      "Pure Formation\n",
      "-1.06923334431\n"
     ]
    }
   ],
   "source": [
    "print ft_pure_formation\n",
    "scores = cross_val_score(LogisticRegression(), pure_formation[ft_pure_formation], pure_formation['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Pure Formation\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax\n",
      "-0.987484303268\n",
      "Mean\n",
      "-0.991968851075\n",
      "Normal\n",
      "-0.981429559041\n"
     ]
    }
   ],
   "source": [
    "# Dados com feature Engineering total\n",
    "data_min = pd.DataFrame()\n",
    "data_mean = pd.DataFrame()\n",
    "for column in ft:\n",
    "    data_min[column]=(data[column] - data[column].min()) / (data[column].max()-data[column].min())\n",
    "for column in ft:\n",
    "    data_mean[column]=(data[column] - data[column].mean()) / data[column].std()\n",
    "\n",
    "    \n",
    "scores = cross_val_score(LogisticRegression(), data_min[ft], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"MinMax\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data_mean[ft], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Mean\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[ft], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Normal\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H    4042\n",
      "A    2528\n",
      "D    2221\n",
      "Name: Output, dtype: int64\n",
      "0.459788419975\n"
     ]
    }
   ],
   "source": [
    "#Classificador mais simple possivel\n",
    "print data['Output'].value_counts()\n",
    "\n",
    "print 4042./data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax\n",
      "-0.987484303268 0.025794254341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean\n",
      "-0.991968851075 0.0279115513172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/felipef/anaconda2/envs/gl-env/lib/python2.7/site-packages/sklearn/metrics/scorer.py:127: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), data_min[ft], data['Output'], cv=10, scoring='log_loss')\n",
    "print \"MinMax\"\n",
    "print scores.mean(),scores.std()\n",
    "scores = cross_val_score(LogisticRegression(), data_mean[ft], data['Output'], cv=10, scoring='log_loss')\n",
    "print \"Mean\"\n",
    "print scores.mean(),scores.std()\n",
    "scores = cross_val_score(LogisticRegression(), data[ft], data['Output'], cv=10, scoring='log_loss')\n",
    "print \"Normal\"\n",
    "print scores.mean(),scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_range=range(50,200)\n",
    "k_score=[]\n",
    "for k in k_range:\n",
    "    scores = cross_val_score((KNeighborsClassifier(n_neighbors=k)), data[ft], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "    k_score.append(scores.mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFkCAYAAACXcsmHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X98ZXV95/HXZwKVFR+OI6ygLaCdJCNoiyRDHV1g7BrJ\nmLHto7bVvZmJlu1WfVQLnV1F6eoDlV1p/UVtFUXZ+iv1Wle3fbRlZqLxx0wRB9xkoVCQmwT50boi\nTMbRxV+Q+e4f52bmJuTXzZx7T5L7ej4e98G555yc88mXm+Q93+/5nhMpJSRJko7XuqILkCRJa4Oh\nQpIk5cJQIUmScmGokCRJuTBUSJKkXBgqJElSLgwVkiQpF4YKSZKUC0OFJEnKhaFCkiTlovBQERFX\nRsSRWa87i65LkiTV54SiC6i6A3gxENX3jxVYiyRJWoaVEioeSyk9VHQRkiRp+Qof/qjqiIh/jYiJ\niBiMiDOKLkiSJNUnin70eUT0Ak8C7gaeDrwdeAbw3JTSI3PsfwrQC9wL/KRphUqStPqdBDwTGEop\nHcz74IWHitkiYj1wH7ArpfTxObb3A3/V9MIkSVo7dqSUPpP3QVfKNRVHpZQOR0QFaJ9nl3sBBgcH\nOfvss5tW12q3a9currnmmqLLWHVst/rZZstju9XPNqvfXXfdxc6dO6H6tzRvKy5URMSTyALFp+bZ\n5ScAZ599Nl1dXU2ra7Vbv3697bUMtlv9bLPlsd3qZ5sdl4ZcPlD4hZoR8Z6IuCgizoqIFwJ/AzwK\nlAsuTZIk1WEl9FT8AvAZ4BTgIeBGYEsjLiCRJEmNU3ioSCmViq5BkiQdv8KHP9QcpZLZbTlst/rZ\nZstju9XPNlt5VtyU0sVERBcwMjIy4gU6kiTVYXR0lO7uboDulNJo3se3p0KSJOXCUCFJknJhqJAk\nSbkwVEiSpFwYKiRJUi4MFZIkKReGCkmSlAtDhSRJyoWhQpIk5cJQIUmScmGokCRJuTBUSJKkXBgq\nJElSLgwVkiQpF4YKSZKUC0OFJEnKhaFCkiTlwlAhSZJyYaiQJEm5MFRIkqRcGCokSVIuDBWSJCkX\nhgpJkpQLQ4UkScqFoUKSJOXCUCFJknJhqJAkSbkwVEiSpFwYKiRJUi4MFZIkKReGCkmSlAtDhSRJ\nyoWhQpIk5cJQIUmScmGokCRJuTBUSJKkXBgqJElSLgwVkiQpF4YKSZKUixURKiLi9RHx7Yj4cUQc\niIjzi65JkiTVp/BQERGvBN4HXAmcB9wGDEXEqYUWJkmS6lJ4qAB2AdellD6VUvoW8DrgR8B/LLYs\nSZJUj0JDRUScCHQDX55el1JKwDDwgqLqkiRJ9Su6p+JUoA14cNb6B4HTm1+OJElarhOKLmC5du3a\nxfr162esK5VKlEqlgiqSJGnlKJfLlMvlGesOHz7c0HNGNtpQjOrwx4+A30op/V3N+k8A61NKvznH\n13QBIyMjI3R1dTWtVkmSVrvR0VG6u7sBulNKo3kfv9Dhj5TSo8AI8OLpdRER1fc3FVWXJEmq30oY\n/ng/8ImIGAFuIZsN8kTgE0UWJUmS6lN4qEgpfa56T4p3AqcBtwK9KaWHiq1MkiTVo/BQAZBSuha4\ntug6JEnS8hU9pVSSJK0RK6KnQtLyVSoV9u3bR0Rw5plnct999x1dnpqaoq2tbca6epeXewzP7bkb\neYypqSna29vp6Ogo+kdQNQwVUp0qlQoTExN1/fJrxC/bO++8k4985GPcffe3gCNAVF9HyDohZ6+r\nd3m5x/DcnruRx5jeN9Pb20e5PMiGDRtQ8QwVUo2F/tX//e9/n3e/+32MjNzCyvhlC3AisB44C7iL\nbOLUWcD9wJmz1tW7vNxjeG7P3chj3A/8OXARsJ/h4UsplXayd+8NaAVIKa2qF9AFpJGRkSTVuvvu\nu9NHP/rR9LGPfSwNDQ3NWN69e/fj1tUuX3PNNWnTpnMSrEtAgqhZnv5vW4L1CZ6X4AkJNiyy/NQ6\n9q33GE+u1kSC98yxPNe6epeb/XWe23MvZXkwQap5fToBqVKpFP0raFUYGRmZbtOu1IC/0fZUaNWZ\n3ZuQzzAALPyv/qcB3wLeCrypuv9/W2T5PXXsW+8xLq1uo1obs5bnWlfvcrO/znN77qUsX8RMWwEY\nHx/3+ooVwFChFW/6GoZHHnmEq656F//0T7eR7zDAE4AfAD9l8T/sK+WX7XaOhYrv1az/3gLr6l1u\n9td5bs+9lOX9wI6a9fsAaG9vRytAI7o/GvnC4Y+WcfDgwXTBBVurXXXrqq9GDAO8qWb5k3Msf3IJ\nx2h2t/Bggr452qMZQy9FDvt4bs/91JQNedyf4NOpre2pqbe3r+hfV6tGo4c/Cg8JdRdsqFjz7r77\n7nTNNdekk09en45dw7A+zf3HtZ5AMN/y1+Y59uw/7Mv55dfIX7YfSXBhWvg6kDiO5WZ/nef23PXs\nm716e/vS5ORk0b+2Vg2vqVDLmJyc5Ld/+5V89atf4djvjOmhh+lhCMh/GOBfgD7gy8C7gOeRDYtM\nL19d/e+9wDPJ7iQfwKOLLK8DJpe473KO8bqj38Gzn302r3vdaznnnHO47777ADjrrLN47LHHOOGE\nE2asq3d5ucfw3J67kcd47LHHvE/FCmSo0IrxG7/xcm688QDwJLJrHOBYgJgvPCw1ENw1z/a7gD+s\n7vdD4OvM/4d9XfU9QKK7ezMDAzs4+eSTC/1lu3XrVn+xSloRDBUq3OTkJBdfvI2RkW9W19TObJgO\nEPOFh6UGgsV6BZb+r37/hSRJczNUqFCTk5N0dp7DwYM/rFk73StR29NwKVmYmCs85DcM4L/6JWn5\nDBUq1MUXb+PgwQeZOW1zulfiJo5dw7CO2vBwzjnP5TWv+U8zwoOBQJKKZahQIR4/5PFK4KtkwxvT\nQxo/Ab5S3X6E7u7zufzyN3LeeecZHiRpBTJUqOluueUWXvKSbfzgBz+tWbsfGCQLF1+mtlfi3HPP\n4/rrP8rmzZubW6gkqS7rii5ArWNycpJt27bz/Odv4Qc/OAS8o7pl+pqJG4D/AfwpcBIdHR1UKhVu\nvXXUQCFJq4A9FWqa/v4BvvSlr5PdfwKODXlMXzsxcHTfU045jZtvvtnHGUvSKmJPhZri85//PEND\nuzly5DU1a6eHPF7Isfs/wObN5zM2dpeBQpJWGUOFGmp6yON3fucV1TXbq/+tHfL4CNnsjyeyefP5\nfPObtxgoJGkVcvhDDfX4IY/Z00VnDnl88YtDzS5RkpQTeyrUMJVKZdaQx78n6534dbLnwh0b8rjg\ngq0OeUjSKmeoUENMTk5SKu2ovpse8nglsIVsuuj0/SeCL3zhC/zjP37NQCFJq5yhQg3R3z/ArbeO\nVd9ND3lcAZSAfcAbWbduPb29L+XlL395UWVKknLkNRXK3S233MLQ0G6ymR2f4dhzO35C7TUUL3lJ\nH+XyYCE1SpLyZ6hQ7i655PeqSxeR9VDspPYOmRs3dvDZz37GG1pJ0hrj8IdyMzk5yYUXbuXOO++o\nrtkPbCCbNloB3gjAnj03GCgkaQ2yp0K56e8f4KabRqvvpmd6JGArcDPwMbq6zvdhYJK0RhkqlIvp\n6aPHHmH+SuAkaq+hgHVcd921RZQnSWoChz+Ui1tvnb7nxCuZa6ZHxJPp7d3msIckrWH2VCgXf/EX\nH6ouTT/PYye1vRQXXLDVmR6StMYZKnTcKpUKN964n2PP80hkz/P4a+BKNm9+Dvv3f63ACiVJzWCo\n0HGbmJioLn0KeAuzr6N405ve2PyiJElN5zUVOi6Tk5O8611/Un33TxybPjp90eYRzjvvvKLKkyQ1\nkT0VOi79/QN84xt3MHPoYytwkLa2q+np6XMKqSS1CEOFlu3YNNJBjt0589jQxwtf6MWZktRKHP7Q\nsh2bRnoRM++c+UkArrjizT55VJJaiKFCyzZzGum0DqY/Vu3t7c0uSZJUIIc/tCxzTyPdSnazqzdw\n4YVbvZZCklqMoUJ1m5ycpFTaUX039zTSN7zhD5pfmCSpUIUOf0TEvRFxpOY1FRGXF1mTFtffP8Ct\nt45V3zmNVJKUKbqnIgFvBT4GRHXdD4srR4uZOePjMziNVJI0rehQAfD/UkoPFV2ElubY3TMvYq5p\npOeee77TSCWpRa2E2R9viYiHI2I0It4YEW1FF6T5bdy4sbq0n5nTSLNbcX/2s3/lNFJJalFF91R8\nABgFJoEXAn8CnM70XyitOKeeeiqnnHIaBw++nmPDHjfT1vaXDntIUovLPVRExNXAmxfYJQFnp5Qq\nKaU/q1l/R0T8DLguIq5IKT2ad206fv39Axw69FPgWdQOezzlKac57CFJLa4RPRXvBT6+yD73zLP+\nFrKangmMzbMPALt27WL9+vUz1pVKJUql0tKqVN1mXqS5g+x/0Tjwzxw8+CYefvhhhz4kaYUol8uU\ny+UZ6w4fPtzQc0ZKqaEnqEdE7AA+AZyaUprzO4+ILmBkZGSErq6uZpbX8vbs2UNfXx9wP3BGzZYH\ngDPZvXs3L33pS4spTpK0qNHRUbq7uwG6U0qjeR+/sGsqImIL8Hzgq2TTSF8IvB/49HyBQsWaeZHm\njpot+wBvyy1Jra7ICzV/CvwH4ErgCcC3gfcB1xRYkxbQ2dnJBRds5aab/pAjR47dlrut7TIv0pQk\nFRcqUkr/B3hBUedXfSYnJ+nvH+DGG/eRzUQ+dpFmT0+fF2lKklbEfSq0CvT3DzA8fIDsIs17gfey\nbt2TuOCCrezde4MXaEqSDBVa3PSsj6mpPye7luIM4L9w5MiHufHGfYyNLThRR5LUIgwVWtTMW3PX\n2grA+Ph4U+uRJK1Mhgotauasj1rO+pAkHWOo0KI6Ozvp7e2jre1SsmsqHgAGaWu7jN5eZ31IkjKG\nCi3JVVe9nXPP3Ug26+NMYICeni3O+pAkHVX0A8W0wk1PJc1uz53p6trMddd9mM2bNxdYmSRppbGn\nQguaOZX0fmCQ2267h7e+9cqCK5MkrTT2VGhej3+AGMAOpqYSQ0MDjI2NeT2FJOkoeyo0L6eSSpLq\nYajQvJxKKkmqh6FC83IqqSSpHoYKLahcHuQFL/glnEoqSVqMoULzmpycpFTaWX0yaeaCC7ZSLg/6\nADFJ0uMYKjSvuaaTfuMbt1Mq7Sy4MknSSuSUUs3J6aSSpHrZU6E5OZ1UklQvQ4Xm5HRSSVK9DBWa\nk9NJJUn1MlRoXuXyID09W3A6qSRpKbxQU/PasGEDe/fewNjYGOPj47S3t9tDIUmal6FCi+ro6DBM\nSJIWZajQvCqVChMTE/ZQSJKWxGsq9DiTk5Ns27adTZs20dfXR2dnJ9u2befQoUNFlyZJWsEMFXqc\nue6kOTx8wDtpSpIW5PCHZvBOmpKk5bKnQjN4J01J0nIZKjSDd9KUJC2XoUIzeCdNSdJyGSr0ON5J\nU5K0HF6oqcfxTpqSpOUwVGhe3klTklQPQ4Xm5N00JUn18poKzeDdNCVJy2Wo0AzeTVOStFwOf+go\n76YpSToe9lToKO+mKUk6HoYKHeXdNCVJx8NQoaO8m6Yk6XgYKjSDd9OUJC2XF2pqBu+mKUlaroaF\nioj4Y2A78Dzgpymlp86xzxnAR4AXAT8EPgW8JaV0pFF1aWm8m6YkqV6NHP44Efgc8OG5NkbEOmA3\nWbDZArwa+F3gnQ2sSZIkNUjDQkVK6R0ppQ8At8+zSy/wbGBHSun2lNIQ8Dbg9RHhsIwkSatMkRdq\nbgFuTyk9XLNuCFgPPKeYklSpVNizZw9jY2NFlyJJWmWKDBWnAw/OWvdgzTY1kc/8kCQdr7qGGSLi\nauDNC+ySgLNTSpXjqmoJdu3axfr162esK5VKlEqlRp96TZr5zI+LgP0MD19KqbSTvXtvKLg6SVK9\nyuUy5XJ5xrrDhw839JyRUlr6zhGnAKcssts9KaXHar7m1cA1s2d/RMQ7gF9LKXXVrHsmcA9wXkrp\ntnlq6AJGRkZG6OrqmmsX1alSqbBp0yZmPvOD6vsBKpWKM0EkaQ0YHR2lu7sboDulNJr38evqqUgp\nHQQO5nTubwB/HBGn1lxXcTFwGLgzp3NoCZbyzA9DhSRpMQ27piIizoiIc4GzgLaIOLf6Orm6yxfJ\nwsOnI+KXI6IXuAr4YErp0UbVpcfzmR+SpDw0curmO4FX1byf7mb5VWB/SulIRLyM7D4WNwGPAJ8A\nrmxgTZrD9DM/hocvZWoqkfVQ7KOt7TJ6enzmhyRpaRoWKlJKlwCXLLLPA8DLGlWDlq5cHqRU2snQ\n0MDRdT09fT7zQ5K0ZN5kSoDP/JAkHT9DhWbwmR+SpOXy0eeSJCkX9lToqEqlwsTEhEMfkqRlsadC\n3qJbkpQLQ4Vm3aL7fmCQ4eEDlEo7C65MkrSaOPzR4iqVCkNDu5l5i+4dTE0lhoYGGBsbcyhEkrQk\n9lS0uKXcoluSpKUwVLQ4b9EtScqLoaLFTd+iu63tUrIhkAeAQdraLqO311t0S5KWzlAhyuVBenq2\nAAPAmcAAPT1bvEW3JKkuXqgpb9EtScqFoUJHeYtuSdLxcPhDkiTlwlAhSZJyYaiQJEm5MFRIkqRc\nGCokSVIuDBWSJCkXhgpJkpQL71MhKpUKExMT3vRKknRc7KloYZOTk2zbtp1NmzbR19dHZ2cn27Zt\n59ChQ0WXJklahQwVLay/f4Dh4QNkDxK7HxhkePgApdLOgiuTJK1GDn+0qEqlwtDQbrJAsaO6dgdT\nU4mhoQHGxsYcCpEk1cWeihY1MTFRXbpo1patAIyPjze1HknS6meoaFEbN26sLu2ftWUfAO3t7U2t\nR5K0+hkqWlRnZye9vX20tV1KNgTyADBIW9tl9Pb2OfQhSaqboaKFlcuD9PRsAQaAM4EBenq2UC4P\nFlyZJGk18kLNFrZhwwb27r2BsbExxsfHvU+FJOm4GCpER0eHYUKSdNwc/pAkSbkwVEiSpFwYKiRJ\nUi4MFZIkKReGCkmSlAtDhSRJyoWhQpIk5cJQIUmScmGokCRJuTBUSJKkXBgqJElSLhoWKiLijyPi\n6xHxSERMzrPPkVmvqYh4RaNq0uNVKhX27NnD2NhY0aVIkla5RvZUnAh8DvjwIvu9GjgNOB14OvC3\nDaxJVZOTk2zbtp1NmzbR19dHZ2cn27Zt59ChQ0WXJklapRoWKlJK70gpfQC4fZFdD6eUHkopfa/6\n+lmjatIx/f0DDA8fAAaB+4FBhocPUCrtLLgySdJqtRKuqfhQRDwUETdHxCVFF9MKKpUKQ0O7mZr6\nc2AHcAawg6mpDzA0tNuhEEnSshQdKt4GvALoAT4PXBsRbyi2pLVvYmKiunTRrC1bARgfH29qPZKk\nteGEenaOiKuBNy+wSwLOTilVlnK8lNJ/r3l7W0ScDLwJ+OBiX7tr1y7Wr18/Y12pVKJUKi3l1C1t\n48aN1aX9ZD0V0/YB0N7e3uySJEk5K5fLlMvlGesOHz7c0HNGSmnpO0ecApyyyG73pJQeq/maVwPX\npJSeuoTj9wF/D5yUUnp0nn26gJGRkRG6urqWXLtm2rZtO8PDB5ia+gBZD8U+2touo6dnC3v33lB0\neZKkBhgdHaW7uxugO6U0mvfx6+qpSCkdBA7mXUSN84BD8wUK5adcHqRU2snQ0MDRdT09fZTLgwVW\nJUlazeoKFfWIiDOApwJnAW0RcW5103hK6ZGIeBnZVNIDwE+Ai4ErgHc3qiYds2HDBvbuvYGxsTHG\nx8dpb2+no6Oj6LIkSatYw0IF8E7gVTXvp7tZfpVsMP9R4PXA+4EAxoE/Sild38CaNEtHR4dhQpKU\ni4aFipTSJcC8U0RTSkPAUKPOL0mSmqvoKaWSJGmNMFRIkqRcGCokSVIuDBWSJCkXhgpJkpQLQ4Uk\nScqFoUKSJOXCUCFJknJhqJAkSbkwVEiSpFwYKiRJUi4MFZIkKReNfEqpVrBKpcLExISPPJck5cae\nihYzOTnJtm3b2bRpE319fXR2drJt23YOHTpUdGmSpFXOUNFi+vsHGB4+AAwC9wODDA8foFTaWXBl\nkqTVzuGPFlKpVBga2k0WKHZU1+5gaioxNDTA2NiYQyGSpGWzp6KFTExMVJcumrVlKwDj4+NNrUeS\ntLYYKlrIxo0bq0v7Z23ZB0B7e3tT65EkrS2GihbS2dlJb28fbW2Xkg2BPAAM0tZ2Gb29fQ59SJKO\ni6GixZTLg/T0bAEGgDOBAXp6tlAuDxZcmSRptfNCzRazYcMG9u69gbGxMcbHx71PhSQpN4aKFtXR\n0WGYkCTlyuEPSZKUC0OFJEnKhaFCkiTlwlAhSZJyYaiQJEm5MFRIkqRcGCokSVIuDBWSJCkXhgpJ\nkpQLQ4UkScqFoUKSJOXCUCFJknJhqJAkSbkwVEiSpFwYKiRJUi4MFZIkKReGCkmSlAtDhSRJykVD\nQkVEnBUR10fEPRHxo4gYi4i3R8SJs/Y7IyJuiIhHIuK7EfHuiDDoSJK0Cp3QoOM+Gwjg94EJ4LnA\n9cATgcsBquFhN/AdYAvwDODTwM+AtzaoLkmS1CAN6RVIKQ2llH4vpfTllNK9KaV/AN4LvLxmt16y\n8LEjpXR7SmkIeBvw+ohoVNiRJEkN0syhhqcAkzXvtwC3p5Qerlk3BKwHntPEuiRJUg6aEioioh14\nA/CRmtWnAw/O2vXBmm2SJGkVqStURMTVEXFkgddURHTO+pqfB/YAf51S+ss8i5ckSStHvdcuvBf4\n+CL73DO9EBHPAL4C3JhSeu2s/b4LnD9r3Wk12xa0a9cu1q9fP2NdqVSiVCot9qUtr1KpMDExQXt7\nOx0dHUWXI0lqgHK5TLlcnrHu8OHDDT1npJQac+Csh+IrwDeBgTTrRBGxDfh74OnT11VExGuAPwWe\nllJ6dJ7jdgEjIyMjdHV1NaT2tWpycpL+/gGGhnYfXdfb20e5PMiGDRsKrEyS1Ayjo6N0d3cDdKeU\nRvM+fqPuU/EM4GvAfWRTSJ8WEadFxGk1u30RuBP4dET8ckT0AlcBH5wvUOj49PcPMDx8ABgE7gcG\nGR4+QKm0s+DKJElrQaOmbr4E+MXq64HqugAS0AaQUjoSES8DPgzcBDwCfAK4skE1tbRKpVLtoRgE\ndlTX7mBqKjE0NMDY2JhDIZKk49Ko+1R8MqXUNuu1LqXUNmu/B1JKL0spPSmldFpK6c0ppSONqKnV\nTUxMVJcumrVlKwDj4+NNrUeStPZ4S+wWsXHjxurS/llb9gHQ3t7e1HokSWuPoaJFdHZ20tvbR1vb\npWRDIA8Ag7S1XUZvb59DH5Kk42aoaCHl8iA9PVuAAeBMYICeni2Uy4MFVyZJWgt8xkYL2bBhA3v3\n3sDY2Bjj4+Pep0KSlCtDRQvq6OgwTEiScufwhyRJyoWhQpIk5cJQIUmScmGokCRJuTBUSJKkXBgq\nJElSLgwVkiQpF4YKSZKUC0OFJEnKhaFCkiTlwlAhSZJyYaiQJEm5MFRIkqRcGCokSVIuDBWSJCkX\nhgpJkpQLQ4UkScqFoUKSJOXCUCFJknJhqJAkSbkwVEiSpFwYKiRJUi4MFZIkKReGCkmSlAtDhSRJ\nysUJRReg5qlUKkxMTNDe3k5HR0fR5UiS1hh7KlrA5OQk27ZtZ9OmTfT19dHZ2cm2bds5dOhQ0aVJ\nktYQQ0UL6O8fYHj4ADAI3A8MMjx8gFJpZ8GVSZLWEoc/1rhKpcLQ0G6yQLGjunYHU1OJoaEBxsbG\nHAqRJOXCnoo1bmJiorp00awtWwEYHx9vaj2SpLXLULHGbdy4sbq0f9aWfQC0t7c3tR5J0tplqFjj\nOjs76e3to63tUrIhkAeAQdraLqO3t8+hD0lSbgwVLaBcHqSnZwswAJwJDNDTs4VyebDgyiRJa4kX\naraADRs2sHfvDYyNjTE+Pu59KiRJDWGoaCEdHR2GCUlSwzj80SLK5XLRJaxKtlv9bLPlsd3qZ5ut\nPA0JFRFxVkRcHxH3RMSPImIsIt4eESfO2u/IrNdURLyiETW1On/4lsd2q59ttjy2W/1ss5WnUcMf\nzwYC+H1gAngucD3wRODyWfu+Gthb3R/g+w2qSZIkNVBDQkVKaQgYqll1b0S8F3gdjw8Vh1NKDzWi\nDkmS1DzNvKbiKcDkHOs/FBEPRcTNEXFJE+uRJEk5asrsj4hoB94A/OdZm94GfAX4EXAxcG1EnJxS\n+uAChzsJ4K677mpEqWvW4cOHGR0dLbqMVcd2q59ttjy2W/1ss/rV/O08qRHHj5TS0neOuBp48wK7\nJODslFKl5mt+Hvga8JWU0msXOf7bgUtSSmctsE8/8FdLLlqSJM22I6X0mbwPWm+oOAU4ZZHd7kkp\nPVbd/xnAV4GbUkqLDm1ERB/w98BJKaVHF6ihF7gX+MmSi5ckSScBzwSGUkoH8z54XaGirgNnPRRf\nAb4JDKQlnCgi/iuwK6V0akOKkiRJDdOQayqqPRRfA75NNtvjaRHZjNGU0oPVfV4GnAYcIOtxuBi4\nAnh3I2qSJEmN1agLNV8C/GL19UB1XZBdc9FWff8o8Hrg/dVt48AfpZSub1BNkiSpgRo2/CFJklqL\nz/6QJEm5MFRIkqRcrKpQERH3zvEAsstn7XNGRNwQEY9ExHcj4t0Rsaq+z7xFxOsj4tsR8eOIOBAR\n5xdd00oREVfO8WC7O2ft886I+E714Xhfqt7MraVExIUR8XcR8a/VNvr1OfZZsJ0i4gkR8aGIeDgi\nfhgRn4+IpzXvu2iuxdosIj4+x2dv96x9Wq3NroiIWyLiBxHxYET8TUR0zrGfn7UaS2m3Zn3eVtsf\n2wS8lWzWyOnA04G/mN5YDQ+7yS5A3UL2sLLfBd7Z7EJXioh4JfA+4ErgPOA2YCginLZ7zB0c+0yd\nDlwwvSEi3kx2N9jXAL8CPELWfj9XQJ1FOhm4FfgDsp/DGZbYTn8GbAd+C7gIeAbwhcaWXagF26xq\nDzM/e6VZ21utzS4k+53+fKAHOBH4YkT8m+kd/KzNadF2q2r85y2ltGpeZFNUL11g+0vJZpWcWrPu\ntcAh4ISi6y+ozQ4AH6h5H8C/AJcXXdtKeJGFrdEFtn+H7N4p0++fDPwYeEXRtRfYZkeAX6+nnarv\nfwr8Zs1y8sN3AAAD+UlEQVQ+m6rH+pWiv6eC2uzjwP9a4Gtaus2q3++p1e/3gpp1ftaW125N+byt\ntp4KgLdUu2ZGI+KNEdFWs20LcHtK6eGadUPAeuA5Ta1yBYiIE4Fu4MvT61L2SRkGXlBUXStQR7WL\neiIiBiPiDICIeBZZmq9tvx8AN2P7HbXEdtpM1oNYu8/dwP20dlu+qNpd/a2IuDYinlqzrRvb7Clk\nvTyT4GetDjParUbDP29NeaBYjj4AjJI11AuBPyH7gL2xuv104MFZX/NgzbbbmlDjSnIq2X1B5mqT\nTc0vZ0U6QDZEdjfZcNrbgf0R8Vyyz0xi7vY7vXklrnhLaafTgJ9V/wDMt0+r2UPWtfxtYCNwNbA7\nIl5QDf+n08JtFhFB1h1/Y0pp+jonP2uLmKfdoEmft8JDRdTxkLKU0p/VrL8jIn4GXBcRV6R5nhUi\nLSSlNFTz9o6IuAW4D3gF8K1iqlIrSCl9rubtP0fE7cAE8CKyZya1umuBc4B/V3Qhq8yc7dasz9tK\nGP54L/DsBV5nA/fM87W3kAWjZ1bff5cspdY6rWZbq3kYmGLuNmnF9lhUSukwUAHaydoosP0Ws5R2\n+i7wcxHx5AX2aWkppW+T/cxOz2Ro2TaLiA8CfcCLUkr/t2aTn7UFLNBuj9Ooz1vhoSKldLDaC7HQ\n67F5vvw8sotIvld9/w3gl2bNbLgYOAzcSYup9t6MAC+eXlftGnsxcFNRda1kEfEksh+y71R/6L7L\nzPZ7MtkV1rZf1RLbaQR4bNY+m4AzyX5uW15E/ALZU6Cn/xi0ZJtV/zD+BvCrKaX7a7f5WZvfQu02\nz/6N+bwVfZVqHVezbgEuA34ZeBawg2ys5y9r9llHdt3Enup+vdV9riq6/gLb7RXAj4BXkfX8XAcc\nBP5t0bWthBfwHrKpU2eRXafzpepn5pTq9sur7fVrwC8BfwuMAT9XdO1NbqeTgXOB55EF+T+qvj9j\nqe1E1i37bbLu1m7g68A/Fv29FdFm1W3vJvtjeFb1F/n/Bu4CTmzhNruWbLbehWT/Qp5+nVSzj5+1\nOtutmZ+3whujjkY7jywtTZLNS76j+uE6cdZ+ZwD/APy/6h+HPwXWFV1/wW33B8C9ZNOuvgFsLrqm\nlfICymRTbH9MdpXzZ4Bnzdrn7WTT2H5ENpuovei6C2inrdU/jFOzXrWhfsF2Ap5ANpf+YeCHwP8E\nnlb091ZEmwEnAXvJ/tX9E7Ih3g8zK+y3YJvN1V5TwKtm7ednrY52a+bnzQeKSZKkXBR+TYUkSVob\nDBWSJCkXhgpJkpQLQ4UkScqFoUKSJOXCUCFJknJhqJAkSbkwVEiSpFwYKiRJUi4MFZIkKReGCkmS\nlIv/DxyMMCICNLf9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f629f429310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(k_range,k_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.09027134044\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score((KNeighborsClassifier(n_neighbors=100)), data[ft], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "k_range=[300,500,800,1000,1300,1500,1800,2000,3000,4000,5000]\n",
    "k_score=[]\n",
    "for k in k_range:\n",
    "    scores = cross_val_score((RandomForestClassifier(n_estimators=k, max_depth=3, n_jobs=-1)), data[ft], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "    k_score.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(k_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(k_score)\n",
    "plt.scatter([300,500,800,1000,1300,1500,1800,2000,3000,4000,5000],k_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "k_range=[1000,2000,3000,4000]\n",
    "k_score=[]\n",
    "for k in k_range:\n",
    "    scores = cross_val_score((GradientBoostingClassifier(n_estimators=k)), data[ft], data['Output'], cv=5, scoring='accuracy')\n",
    "    k_score.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(k_score)\n",
    "plt.scatter([1000,2000],k_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "dt = SelectKBest(chi2, k=48).fit_transform(data[ft],data['Output'])\n",
    "print dt.shape\n",
    "print data.shape\n",
    "print dt[0]\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), dt, data['Output'], cv=10, scoring='log_loss')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[ft],data['Output'],test_size=0.33)\n",
    "\n",
    "lm = LogisticRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "prob= lm.predict_proba(X_test)\n",
    "pre =  lm.predict(X_test)\n",
    "print prob[0],pre[0]\n",
    "print pre\n",
    "\n",
    "print lm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['home_V', 'home_D', 'home_E', 'home_GF', 'home_AVG_GF', 'home_GS', 'home_AVG_GS', 'home_VG', 'home_DG', 'home_EG', 'home_GFG', 'home_AVG_GFG', 'home_GSG', 'home_AVG_GSG', 'away_V', 'away_D', 'away_E', 'away_GF', 'away_AVG_GF', 'away_GS', 'away_AVG_GS', 'away_VG', 'away_DG', 'away_EG', 'away_GFG', 'away_AVG_GFG', 'away_GSG', 'season', 'stage', 'league_id', 'a_date', 'h_date', 'B365H', 'B365D', 'B365A', 'formation_h', 'formation_a']\n"
     ]
    }
   ],
   "source": [
    "play_style = ['h_buildUpPlaySpeed',\n",
    "       'h_buildUpPlaySpeedClass', 'h_buildUpPlayDribblingClass',\n",
    "       'h_buildUpPlayPassing', 'h_buildUpPlayPassingClass',\n",
    "       'h_buildUpPlayPositioningClass', 'h_chanceCreationPassing',\n",
    "       'h_chanceCreationPassingClass', 'h_chanceCreationCrossing',\n",
    "       'h_chanceCreationCrossingClass', 'h_chanceCreationShooting',\n",
    "       'h_chanceCreationShootingClass', 'h_chanceCreationPositioningClass',\n",
    "       'h_defencePressure', 'h_defencePressureClass',\n",
    "       'h_defenceAggression', 'h_defenceAggressionClass',\n",
    "       'h_defenceTeamWidth', 'h_defenceTeamWidthClass',\n",
    "       'h_defenceDefenderLineClass', 'a_buildUpPlaySpeed',\n",
    "       'a_buildUpPlaySpeedClass', 'a_buildUpPlayDribblingClass',\n",
    "       'a_buildUpPlayPassing', 'a_buildUpPlayPassingClass',\n",
    "       'a_buildUpPlayPositioningClass', 'a_chanceCreationPassing',\n",
    "       'a_chanceCreationPassingClass', 'a_chanceCreationCrossing',\n",
    "       'a_chanceCreationCrossingClass', 'a_chanceCreationShooting',\n",
    "       'a_chanceCreationShootingClass', 'a_chanceCreationPositioningClass',\n",
    "       'a_defencePressure', 'a_defencePressureClass',\n",
    "       'a_defenceAggression', 'a_defenceAggressionClass',\n",
    "       'a_defenceTeamWidth', 'a_defenceTeamWidthClass',\n",
    "       'a_defenceDefenderLineClass']\n",
    "\n",
    "fifa_ratings=['h_avg_height', 'h_avg_weight',\n",
    "       'a_avg_height', 'a_avg_weight', 'h_overall', 'h_potential', 'h_def',\n",
    "       'h_mid', 'h_att', 'a_overall', 'a_potential', 'a_def', 'a_mid',\n",
    "       'a_att']\n",
    "base= ['season', 'stage','league_id','a_date', 'h_date','B365H',\n",
    "       'B365D', 'B365A', 'formation_h', 'formation_a']\n",
    "\n",
    "goals = ['home_V', 'home_D', 'home_E', 'home_GF', 'home_AVG_GF', 'home_GS',\n",
    "       'home_AVG_GS', 'home_VG', 'home_DG', 'home_EG', 'home_GFG',\n",
    "       'home_AVG_GFG', 'home_GSG', 'home_AVG_GSG', 'away_V', 'away_D',\n",
    "       'away_E', 'away_GF', 'away_AVG_GF', 'away_GS', 'away_AVG_GS',\n",
    "       'away_VG', 'away_DG', 'away_EG', 'away_GFG', 'away_AVG_GFG',\n",
    "       'away_GSG']\n",
    "\n",
    "print goals+base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), data[fifa_ratings+goals+base], data['Output'], cv=10, scoring='log_loss')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.984984243937\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000, max_depth=3)), data[ft], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_range=[1000,2000,3000,4000,5000]\n",
    "k_score=[]\n",
    "for k in k_range:\n",
    "    scores = cross_val_score((RandomForestClassifier(n_estimators=k, max_depth=3)), data[fifa_ratings+goals+base], data['Output'], cv=10, scoring='accuracy')\n",
    "    k_score.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print k_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base\n",
      "-0.973562814441\n",
      "Ratings\n",
      "-0.984979257755\n",
      "Goals\n",
      "-1.03314259493\n",
      "Style\n",
      "-1.06146631889\n",
      "Base+goals\n",
      "-0.974094074696\n",
      "Base+Ratings\n",
      "-0.97333685394\n",
      "Base+Style\n",
      "-0.979329914618\n",
      "Rating+Goals\n",
      "-0.986844484151\n",
      "Goals+Style\n",
      "-1.03907113122\n",
      "Ratings+Style\n",
      "-0.998159144845\n",
      "base+Rating+Goals\n",
      "-0.974709147966\n",
      "base+Rating+play_style\n",
      "-0.980211581839\n",
      "base+goals+play_style\n",
      "-0.981671730394\n",
      "Rating+goals+play_style\n",
      "-1.0006185998\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), data[base], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[fifa_ratings], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[base+goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base+goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[base+fifa_ratings], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base+Ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[base+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[fifa_ratings+goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Rating+Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Goals+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[fifa_ratings+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Ratings+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[base+fifa_ratings+goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"base+Rating+Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[base+fifa_ratings+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"base+Rating+play_style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[base+goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"base+goals+play_style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[fifa_ratings+goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Rating+goals+play_style\"\n",
    "print scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style\n",
      "-1.08837422037\n",
      "Base+Style\n",
      "-1.00342865589\n",
      "Goals+Style\n",
      "-1.04459693463\n",
      "Ratings+Style\n",
      "-1.00359251103\n",
      "Rating+goals+play_style\n",
      "-0.996481363352\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RandomForestClassifier(n_estimators=1000), data[play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(RandomForestClassifier(n_estimators=1000,n_jobs=4), data[base+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(RandomForestClassifier(n_estimators=1000,n_jobs=4), data[goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Goals+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(RandomForestClassifier(n_estimators=1000,n_jobs=4), data[fifa_ratings+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Ratings+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(RandomForestClassifier(n_estimators=1000,n_jobs=4), data[fifa_ratings+goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Rating+goals+play_style\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base\n",
      "-1.03659004831\n",
      "Ratings\n",
      "-0.994091173579\n",
      "Goals\n",
      "-1.03785982671\n",
      "Style\n",
      "-1.06445276755\n",
      "Base+goals\n",
      "-1.04955993303\n",
      "Base+Ratings\n",
      "-1.00901515738\n",
      "Base+Style\n",
      "-1.07038982999\n",
      "Rating+Goals\n",
      "-0.992641108592\n",
      "Goals+Style\n",
      "-1.04071347198\n",
      "Ratings+Style\n",
      "-1.02397472781\n",
      "base+Rating+Goals\n",
      "-1.02632818715\n",
      "base+Rating+play_style\n",
      "-1.04787193518\n",
      "base+goals+play_style\n",
      "-1.0604808121\n",
      "Rating+goals+play_style\n",
      "-1.01855727069\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[base], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[fifa_ratings], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[base+goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base+goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[base+fifa_ratings], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base+Ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[base+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Base+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[fifa_ratings+goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Rating+Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Goals+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[fifa_ratings+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Ratings+Style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[base+fifa_ratings+goals], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"base+Rating+Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[base+fifa_ratings+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"base+Rating+play_style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[base+goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"base+goals+play_style\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(KNeighborsClassifier(n_neighbors=100), data[fifa_ratings+goals+play_style], data['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Rating+goals+play_style\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print uk['Output'].value_counts()[0]/(uk.shape[0]*1.)\n",
    "print de['Output'].value_counts()[0]/(de.shape[0]*1.)\n",
    "print fr['Output'].value_counts()[0]/(fr.shape[0]*1.)\n",
    "print it['Output'].value_counts()[0]/(it.shape[0]*1.)\n",
    "print pt['Output'].value_counts()[0]/(pt.shape[0]*1.)\n",
    "print es['Output'].value_counts()[0]/(es.shape[0]*1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), uk[base], uk['Output'], cv=10, scoring='log_loss')\n",
    "print \"Base\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mandante_forte = data[data['h_overall']>= (data['a_overall']+3)] \n",
    "visitante_forte = data[data['a_overall']>= (data['h_overall']+3)] \n",
    "iguais = data[abs(data['h_overall'] -(data['a_overall'])) < 3 ] \n",
    "\n",
    "print mandante_forte['Output'].value_counts()[0]/(mandante_forte.shape[0]*1.)\n",
    "print visitante_forte['Output'].value_counts()[0]/(visitante_forte.shape[0]*1.)\n",
    "print iguais['Output'].value_counts()[0]/(iguais.shape[0]*1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mandante_forte.shape[0]+visitante_forte.shape[0]+ iguais.shape[0]\n",
    "\n",
    "print uk.shape[0]+de.shape[0]+es.shape[0]+it.shape[0]+fr.shape[0]+pt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66847826087\n",
      "0.499057196732\n",
      "0.460635881908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[ft],data['Output'], test_size=0.33)\n",
    "\n",
    "treino= pd.concat([X_train,y_train],axis=1)\n",
    "mandante_forte = treino[treino['h_overall']>= (treino['a_overall']+3)] \n",
    "visitante_forte = treino[treino['a_overall']>= (treino['h_overall']+3)] \n",
    "iguais = treino[abs(treino['h_overall'] -(treino['a_overall'])) < 3 ]\n",
    "\n",
    "print mandante_forte['Output'].value_counts()[0]/(mandante_forte.shape[0]*1.)\n",
    "print visitante_forte['Output'].value_counts()[0]/(visitante_forte.shape[0]*1.)\n",
    "print iguais['Output'].value_counts()[0]/(iguais.shape[0]*1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mandante Forte\n",
      "Regressão Logistica - Base\n",
      "-0.814989731478\n",
      "Regressão Logistica - Base-Goals\n",
      "-0.816478929558\n",
      "Regressão Logistica - Base+ratings\n",
      "-0.820619992537\n",
      "Regressão Logistica - Base+goals+ratings\n",
      "-0.823411274004\n",
      "Random - Base\n",
      "-0.852166724971\n",
      "Random - Base-Goals\n",
      "-0.837783283072\n",
      "Random - Base+ratings\n",
      "-0.841615729019\n",
      "Random - Base+goals+ratings\n",
      "-0.834640409641\n"
     ]
    }
   ],
   "source": [
    "print \"Mandante Forte\"\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), mandante_forte[base], mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), mandante_forte[base+goals], mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base-Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), mandante_forte[base+fifa_ratings], mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base+ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), mandante_forte[base+goals+fifa_ratings], mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base+goals+ratings\"\n",
    "print scores.mean()\n",
    "\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),mandante_forte[base] , mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),mandante_forte[base+goals] , mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base-Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),mandante_forte[base+fifa_ratings] , mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base+ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),mandante_forte[base+goals+fifa_ratings] , mandante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base+goals+ratings\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFkCAYAAABvkjJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVI2Bg9JkpSNwUOSJGVj8JAkSdn8f6h4sgOwzH6cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8008e73190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print len(k_score)\n",
    "\n",
    "plt.scatter([100,500,1000,2000],k_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitante Forte\n",
      "Regressão Logistica - Base\n",
      "-1.0036004086\n",
      "Regressão Logistica - Base-Goals\n",
      "-1.01224050007\n",
      "Regressão Logistica - Base+ratings\n",
      "-1.01356365601\n",
      "Regressão Logistica - Base+goals+ratings\n",
      "-1.02250358003\n",
      "Random - Base\n",
      "-1.07802630191\n",
      "Random - Base-Goals\n",
      "-1.03579179506\n",
      "Random - Base+ratings\n",
      "-1.041927169\n",
      "Random - Base+goals+ratings\n",
      "-1.02999456242\n"
     ]
    }
   ],
   "source": [
    "print \"visitante Forte\"\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), visitante_forte[base], visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), visitante_forte[base+goals], visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base-Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), visitante_forte[base+fifa_ratings], visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base+ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), visitante_forte[base+goals+fifa_ratings], visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base+goals+ratings\"\n",
    "print scores.mean()\n",
    "\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),visitante_forte[base] , visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),visitante_forte[base+goals] , visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base-Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),visitante_forte[base+fifa_ratings] , visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base+ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),visitante_forte[base+goals+fifa_ratings] , visitante_forte['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base+goals+ratings\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iguais Forte\n",
      "Regressão Logistica - Base\n",
      "-1.05508327122\n",
      "Regressão Logistica - Base-Goals\n",
      "-1.05845467839\n",
      "Regressão Logistica - Base+ratings\n",
      "-1.05967056878\n",
      "Regressão Logistica - Base+goals+ratings\n",
      "-1.06414120982\n",
      "Random - Base\n",
      "-1.10259356201\n",
      "Random - Base-Goals\n",
      "-1.07685361898\n",
      "Random - Base+ratings\n",
      "-1.07201231689\n",
      "Random - Base+goals+ratings\n",
      "-1.06899597774\n"
     ]
    }
   ],
   "source": [
    "print \"iguais Forte\"\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), iguais[base], iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), iguais[base+goals], iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base-Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), iguais[base+fifa_ratings], iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base+ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), iguais[base+goals+fifa_ratings], iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Regressão Logistica - Base+goals+ratings\"\n",
    "print scores.mean()\n",
    "\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),iguais[base] , iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),iguais[base+goals] , iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base-Goals\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),iguais[base+fifa_ratings] , iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base+ratings\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score((RandomForestClassifier(n_estimators=1000,n_jobs=4)),iguais[base+goals+fifa_ratings] , iguais['Output'], cv=10, scoring='neg_log_loss')\n",
    "print \"Random - Base+goals+ratings\"\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n",
      "0.509194673431\n",
      "0.452480121166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[ft],data['Output'], test_size=0.33)\n",
    "\n",
    "treino= pd.concat([X_train,y_train],axis=1)\n",
    "mandante_forte = treino[treino['h_overall']>= (treino['a_overall']+3)] \n",
    "visitante_forte = treino[treino['a_overall']>= (treino['h_overall']+3)] \n",
    "iguais = treino[abs(treino['h_overall'] -(treino['a_overall'])) < 3 ]\n",
    "\n",
    "print mandante_forte['Output'].value_counts()[0]/(mandante_forte.shape[0]*1.)\n",
    "print visitante_forte['Output'].value_counts()[0]/(visitante_forte.shape[0]*1.)\n",
    "print iguais['Output'].value_counts()[0]/(iguais.shape[0]*1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_H = LogisticRegression()\n",
    "reg_H.fit(mandante_forte[base],mandante_forte['Output'])\n",
    "reg_A = LogisticRegression()\n",
    "reg_A.fit(visitante_forte[base],visitante_forte['Output'])\n",
    "reg_I = LogisticRegression()\n",
    "reg_I.fit(iguais[base],iguais['Output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teste= pd.concat([X_train,y_train],axis=1)\n",
    "m = treino[teste['h_overall']>= (teste['a_overall']+3)] \n",
    "v = treino[teste['a_overall']>= (teste['h_overall']+3)] \n",
    "i = treino[abs(teste['h_overall'] -(teste['a_overall'])) < 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.49989713783\n",
      "-1.21385058598\n",
      "-1.14233720246\n",
      "-1.28536164209\n"
     ]
    }
   ],
   "source": [
    "print reg_H.predict_log_proba(m[base]).mean()\n",
    "print reg_A.predict_log_proba(v[base]).mean()\n",
    "print reg_I.predict_log_proba(i[base]).mean()\n",
    "print (-1.49989713783 + -1.21385058598  + -1.14233720246)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logistica - Base\n",
      "0.532708042354\n",
      "Regressão Logistica - Base\n",
      "0.522581341142\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), data[base], data['Output'], cv=10, scoring='accuracy')\n",
    "print \"Regressão Logistica - Base\"\n",
    "print scores.mean()\n",
    "scores = cross_val_score(LogisticRegression(), data[ft], data['Output'], cv=10, scoring='accuracy')\n",
    "print \"Regressão Logistica - Base\"\n",
    "print scores.mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gl-env]",
   "language": "python",
   "name": "conda-env-gl-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
